{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3_LI XINYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.1981e+00, -4.6451e-01, -1.5665e-01,  ...,  3.5825e-01,\n",
       "            5.0774e-01,  6.4651e-01],\n",
       "          [-6.8014e-01, -1.4383e+00, -4.7001e-01,  ..., -1.5630e+00,\n",
       "           -2.5450e-01, -3.2320e-01],\n",
       "          [ 1.3550e+00,  1.2372e-01, -4.8353e-01,  ..., -1.0282e+00,\n",
       "           -2.1841e+00, -1.1347e-01],\n",
       "          ...,\n",
       "          [-3.4027e-01,  4.8877e-01, -2.0639e-01,  ..., -5.6422e-01,\n",
       "            6.6676e-01,  2.8339e-01],\n",
       "          [ 1.8143e+00,  9.3710e-01, -4.6415e-01,  ..., -3.8587e-01,\n",
       "            5.3576e-01,  1.0744e+00],\n",
       "          [-1.0109e+00, -1.2394e-01,  1.0173e+00,  ..., -4.1536e-01,\n",
       "           -1.1075e+00, -7.1288e-01]],\n",
       "\n",
       "         [[-5.3218e-01,  2.2225e-01,  1.6399e+00,  ..., -2.1652e+00,\n",
       "           -1.6121e+00, -1.9405e+00],\n",
       "          [ 6.0333e-01,  2.0236e-01,  2.1709e-01,  ...,  9.9807e-01,\n",
       "            5.7821e-01, -1.3940e-03],\n",
       "          [-8.1933e-01,  1.1584e+00, -8.7382e-01,  ...,  5.6400e-01,\n",
       "           -5.0604e-01,  2.8894e-01],\n",
       "          ...,\n",
       "          [-1.3834e+00, -5.4926e-01,  9.1383e-02,  ..., -3.4276e-01,\n",
       "           -1.8190e-01, -1.2314e+00],\n",
       "          [-1.3498e-02, -9.4039e-01,  9.4229e-02,  ...,  4.0859e-01,\n",
       "           -4.6288e-01,  1.5426e+00],\n",
       "          [ 6.7242e-01, -5.3654e-01, -5.3562e-02,  ..., -1.9635e+00,\n",
       "           -3.0318e-01, -6.4613e-01]],\n",
       "\n",
       "         [[-5.8637e-01,  2.7115e-01, -3.3076e-01,  ...,  3.7952e-01,\n",
       "           -4.8589e-01,  6.3022e-01],\n",
       "          [-1.6469e+00, -6.2115e-01, -1.4652e+00,  ...,  8.2195e-01,\n",
       "           -9.0441e-01, -2.4933e-01],\n",
       "          [ 5.9998e-01, -1.9030e-01,  3.1271e-01,  ...,  8.5164e-01,\n",
       "           -3.3285e-01, -7.3440e-01],\n",
       "          ...,\n",
       "          [-4.3028e-01, -1.1784e+00, -7.9858e-01,  ...,  2.2030e-02,\n",
       "           -4.6417e-01,  6.7593e-02],\n",
       "          [-2.0615e+00,  2.2833e-01,  2.3063e-01,  ..., -1.5120e-01,\n",
       "           -1.8681e+00,  2.6343e-01],\n",
       "          [ 1.0877e+00,  3.9824e-01,  8.6747e-02,  ..., -5.6319e-01,\n",
       "            7.7769e-01, -7.1005e-01]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 32x32 pixels, 3 channels\n",
    "Input = torch.randn(1,3,32,32)\n",
    "Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: torch.nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.1981, -0.1567,  1.0647,  ...,  1.1957,  0.5077,  0.6465],\n",
       "          [ 1.3550,  0.1237, -0.1990,  ...,  0.2669, -0.2545, -0.1135],\n",
       "          [ 1.3550,  0.1237,  0.0666,  ...,  0.2669,  1.8966,  1.8966],\n",
       "          ...,\n",
       "          [ 1.0952,  1.0952,  0.1387,  ...,  0.3140,  0.6668,  0.6668],\n",
       "          [ 1.8143,  0.9371, -0.0184,  ..., -0.0688,  0.6668,  1.0744],\n",
       "          [ 1.8143,  1.0173,  1.0173,  ..., -0.0688,  0.5358,  1.0744]],\n",
       "\n",
       "         [[ 0.6033,  1.6399,  1.6399,  ...,  0.9981,  0.9981,  0.5782],\n",
       "          [ 1.1584,  1.1584,  0.6733,  ...,  0.9981,  0.9981,  0.5782],\n",
       "          [ 1.1584,  1.1584,  1.3359,  ...,  0.8254,  0.8254,  0.2889],\n",
       "          ...,\n",
       "          [ 0.6181,  0.0914,  1.0566,  ...,  0.3681,  0.9976,  0.9976],\n",
       "          [-0.0135,  0.0942,  0.5793,  ...,  0.4086,  0.4086,  1.5426],\n",
       "          [ 0.6724,  0.0942,  1.9908,  ...,  0.4086,  0.4086,  1.5426]],\n",
       "\n",
       "         [[ 0.2711,  0.2711,  0.9275,  ...,  0.8220,  0.8220,  0.6302],\n",
       "          [ 0.6000,  0.3127,  0.9275,  ...,  0.8516,  0.8516, -0.2493],\n",
       "          [ 1.8494,  1.8494,  0.3127,  ...,  1.7095,  1.7095, -0.0572],\n",
       "          ...,\n",
       "          [ 0.9302,  1.1866,  1.8620,  ...,  0.2336,  0.0220,  1.5565],\n",
       "          [ 0.2283,  0.2306,  0.2951,  ...,  0.6401,  0.0220,  0.2634],\n",
       "          [ 1.0877,  0.3982,  0.2951,  ...,  0.6401,  0.7777,  0.7777]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pytorch\n",
    "layer_1 = torch.nn.MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "output_1 = layer_1(Input)\n",
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(x, pool_param):\n",
    "    out = None\n",
    "    N, C, H, W = x.shape\n",
    "    HH, WW = pool_param['pool_height'], pool_param['pool_width']\n",
    "    stride = pool_param['stride']\n",
    "  \n",
    "    H_out = 1 + (H - HH) // stride\n",
    "    W_out = 1 + (W - WW) // stride\n",
    "  \n",
    "    out = torch.zeros((N, C, H_out, W_out), device=x.device, dtype=x.dtype)\n",
    "    for img in range(N):\n",
    "        for channel in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    out[img, channel, i, j] = torch.max(x[img, channel, i*stride:i*stride+HH, j*stride:j*stride+WW])\n",
    "    cache = (x, pool_param)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.1981, -0.1567,  1.0647,  ...,  1.1957,  0.5077,  0.6465],\n",
       "          [ 1.3550,  0.1237, -0.1990,  ...,  0.2669, -0.2545, -0.1135],\n",
       "          [ 1.3550,  0.1237,  0.0666,  ...,  0.2669,  1.8966,  1.8966],\n",
       "          ...,\n",
       "          [ 1.0952,  1.0952,  0.1387,  ...,  0.3140,  0.6668,  0.6668],\n",
       "          [ 1.8143,  0.9371, -0.0184,  ..., -0.0688,  0.6668,  1.0744],\n",
       "          [ 1.8143,  1.0173,  1.0173,  ..., -0.0688,  0.5358,  1.0744]],\n",
       "\n",
       "         [[ 0.6033,  1.6399,  1.6399,  ...,  0.9981,  0.9981,  0.5782],\n",
       "          [ 1.1584,  1.1584,  0.6733,  ...,  0.9981,  0.9981,  0.5782],\n",
       "          [ 1.1584,  1.1584,  1.3359,  ...,  0.8254,  0.8254,  0.2889],\n",
       "          ...,\n",
       "          [ 0.6181,  0.0914,  1.0566,  ...,  0.3681,  0.9976,  0.9976],\n",
       "          [-0.0135,  0.0942,  0.5793,  ...,  0.4086,  0.4086,  1.5426],\n",
       "          [ 0.6724,  0.0942,  1.9908,  ...,  0.4086,  0.4086,  1.5426]],\n",
       "\n",
       "         [[ 0.2711,  0.2711,  0.9275,  ...,  0.8220,  0.8220,  0.6302],\n",
       "          [ 0.6000,  0.3127,  0.9275,  ...,  0.8516,  0.8516, -0.2493],\n",
       "          [ 1.8494,  1.8494,  0.3127,  ...,  1.7095,  1.7095, -0.0572],\n",
       "          ...,\n",
       "          [ 0.9302,  1.1866,  1.8620,  ...,  0.2336,  0.0220,  1.5565],\n",
       "          [ 0.2283,  0.2306,  0.2951,  ...,  0.6401,  0.0220,  0.2634],\n",
       "          [ 1.0877,  0.3982,  0.2951,  ...,  0.6401,  0.7777,  0.7777]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 1}\n",
    "output_1_ = max_pooling(Input,pool_param)\n",
    "output_1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check the difference\n",
    "print(torch.allclose(output_1, output_1_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2: torch.nn.AvgPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0962, -0.6324,  0.0597,  ..., -0.2484, -0.2379,  0.1441],\n",
       "          [-0.1599, -0.5670, -0.5114,  ..., -0.8272, -1.2575, -0.7188],\n",
       "          [ 0.3953, -0.3254, -0.4904,  ..., -0.5710, -0.4807, -0.1909],\n",
       "          ...,\n",
       "          [ 0.1686,  0.3791, -0.0900,  ..., -0.3786, -0.1874, -0.4608],\n",
       "          [ 0.7250,  0.1888, -0.2262,  ..., -0.6288,  0.0631,  0.6401],\n",
       "          [ 0.4041,  0.3416,  0.1189,  ..., -0.3423, -0.3432, -0.0525]],\n",
       "\n",
       "         [[ 0.1239,  0.5704,  0.1647,  ..., -0.9639, -0.5503, -0.7439],\n",
       "          [ 0.2862,  0.1760, -0.1523,  ..., -0.3240,  0.4086,  0.0899],\n",
       "          [-0.2203, -0.1824,  0.2161,  ...,  0.1222, -0.2320, -0.4706],\n",
       "          ...,\n",
       "          [-0.6109, -0.5306,  0.1321,  ..., -0.0552,  0.1582,  0.0435],\n",
       "          [-0.7216, -0.3260,  0.1702,  ..., -0.1927, -0.1447, -0.0834],\n",
       "          [-0.2045, -0.3591,  0.6527,  ..., -0.7084, -0.5802,  0.0326]],\n",
       "\n",
       "         [[-0.6458, -0.5365, -0.3810,  ...,  0.4611, -0.0472, -0.2524],\n",
       "          [-0.4646, -0.4910, -0.0191,  ...,  0.4160,  0.1091, -0.5552],\n",
       "          [ 0.6730, -0.0068, -0.4456,  ...,  0.6160,  0.3905, -0.4476],\n",
       "          ...,\n",
       "          [-0.1047, -0.1327,  0.4547,  ..., -0.0224, -0.4329,  0.0302],\n",
       "          [-0.8604, -0.3795, -0.1761,  ...,  0.1039, -0.6154, -0.5003],\n",
       "          [-0.0868,  0.2360,  0.1818,  ..., -0.1189, -0.4512, -0.3843]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pytorch\n",
    "layer_2 = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0,ceil_mode=False, count_include_pad=True,divisor_override=None)\n",
    "output_2 = layer_2(Input)\n",
    "output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pooling(x, pool_param):\n",
    "    out = None\n",
    "    N, C, H, W = x.shape\n",
    "    HH, WW = pool_param['pool_height'], pool_param['pool_width']\n",
    "    stride = pool_param['stride']\n",
    "  \n",
    "    H_out = 1 + (H - HH) // stride\n",
    "    W_out = 1 + (W - WW) // stride\n",
    "  \n",
    "    out = torch.zeros((N, C, H_out, W_out), device=x.device, dtype=x.dtype)\n",
    "    for img in range(N):\n",
    "        for channel in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    out[img, channel, i, j] = torch.mean(x[img, channel, i*stride:i*stride+HH, j*stride:j*stride+WW])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0962, -0.6324,  0.0597,  ..., -0.2484, -0.2379,  0.1441],\n",
       "          [-0.1599, -0.5670, -0.5114,  ..., -0.8272, -1.2575, -0.7188],\n",
       "          [ 0.3953, -0.3254, -0.4904,  ..., -0.5710, -0.4807, -0.1909],\n",
       "          ...,\n",
       "          [ 0.1686,  0.3791, -0.0900,  ..., -0.3786, -0.1874, -0.4608],\n",
       "          [ 0.7250,  0.1888, -0.2262,  ..., -0.6288,  0.0631,  0.6401],\n",
       "          [ 0.4041,  0.3416,  0.1189,  ..., -0.3423, -0.3432, -0.0525]],\n",
       "\n",
       "         [[ 0.1239,  0.5704,  0.1647,  ..., -0.9639, -0.5503, -0.7439],\n",
       "          [ 0.2862,  0.1760, -0.1523,  ..., -0.3240,  0.4086,  0.0899],\n",
       "          [-0.2203, -0.1824,  0.2161,  ...,  0.1222, -0.2320, -0.4706],\n",
       "          ...,\n",
       "          [-0.6109, -0.5306,  0.1321,  ..., -0.0552,  0.1582,  0.0435],\n",
       "          [-0.7216, -0.3260,  0.1702,  ..., -0.1927, -0.1447, -0.0834],\n",
       "          [-0.2045, -0.3591,  0.6527,  ..., -0.7084, -0.5802,  0.0326]],\n",
       "\n",
       "         [[-0.6458, -0.5365, -0.3810,  ...,  0.4611, -0.0472, -0.2524],\n",
       "          [-0.4646, -0.4910, -0.0191,  ...,  0.4160,  0.1091, -0.5552],\n",
       "          [ 0.6730, -0.0068, -0.4456,  ...,  0.6160,  0.3905, -0.4476],\n",
       "          ...,\n",
       "          [-0.1047, -0.1327,  0.4547,  ..., -0.0224, -0.4329,  0.0302],\n",
       "          [-0.8604, -0.3795, -0.1761,  ...,  0.1039, -0.6154, -0.5003],\n",
       "          [-0.0868,  0.2360,  0.1818,  ..., -0.1189, -0.4512, -0.3843]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 1}\n",
    "output_2_ = avg_pooling(Input,pool_param)\n",
    "output_2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check the difference\n",
    "print(torch.allclose(output_2, output_2_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3: torch.nn.Conv2d\n",
    "## stride=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.7203e-01, -4.4504e-01,  2.1526e-01,  ...,  9.4919e-01,\n",
       "           -1.0656e-01, -5.6796e-01],\n",
       "          [-6.9558e-01,  4.4238e-01,  3.1154e-01,  ...,  8.8952e-01,\n",
       "           -3.4418e-01,  4.8535e-01],\n",
       "          [ 1.2032e+00, -3.5157e-01,  1.1570e-02,  ...,  4.8008e-01,\n",
       "            8.7856e-02, -4.4224e-01],\n",
       "          ...,\n",
       "          [-5.6077e-01, -3.2963e-01, -4.2985e-01,  ..., -1.0816e-01,\n",
       "           -2.6410e-01, -2.7346e-01],\n",
       "          [-2.4182e-02,  8.9218e-02, -1.4849e-01,  ...,  2.1303e-01,\n",
       "            2.9281e-03, -1.5736e-01],\n",
       "          [ 2.4689e-01,  1.0195e-01,  6.4096e-01,  ...,  3.6735e-01,\n",
       "           -4.6341e-01, -5.6703e-01]],\n",
       "\n",
       "         [[-4.1867e-01,  1.6466e-01, -5.7732e-03,  ...,  2.0410e-01,\n",
       "           -2.3797e-01,  1.3518e-01],\n",
       "          [ 3.2239e-01,  8.8653e-01,  4.9060e-01,  ...,  1.1738e+00,\n",
       "            1.8581e-01,  1.0463e-01],\n",
       "          [ 1.4067e-01, -6.8316e-01,  7.2514e-01,  ...,  1.3588e-01,\n",
       "            7.7709e-01, -3.8446e-01],\n",
       "          ...,\n",
       "          [-1.0492e-01,  2.5560e-01, -4.7244e-01,  ...,  4.5675e-01,\n",
       "            1.5187e-01,  2.3270e-01],\n",
       "          [ 2.0977e-01,  2.5171e-01, -7.7332e-01,  ..., -1.8220e-01,\n",
       "           -1.3236e-01,  9.9698e-01],\n",
       "          [ 6.3577e-01,  2.7215e-01,  7.9916e-01,  ...,  2.6645e-01,\n",
       "           -3.6362e-01, -6.3408e-01]],\n",
       "\n",
       "         [[-2.8971e-01,  2.1798e-01,  2.9415e-01,  ...,  5.0401e-01,\n",
       "           -1.1539e+00,  2.9358e-01],\n",
       "          [-2.8366e-01,  9.2011e-01, -5.4006e-01,  ...,  4.3700e-01,\n",
       "           -7.3780e-01,  2.2404e-01],\n",
       "          [ 2.0314e-01, -7.8640e-01,  7.0324e-01,  ...,  7.9478e-02,\n",
       "           -1.2091e-01, -3.8622e-01],\n",
       "          ...,\n",
       "          [ 6.0303e-02,  2.9337e-01,  6.2083e-02,  ..., -4.6981e-03,\n",
       "            4.3894e-01,  3.1941e-01],\n",
       "          [ 1.4782e-01,  1.3193e-01,  3.2466e-02,  ...,  4.7630e-03,\n",
       "           -2.4785e-01,  3.8520e-01],\n",
       "          [ 1.4039e+00, -5.6947e-03,  9.7006e-02,  ...,  2.7574e-01,\n",
       "            8.0594e-02,  5.7700e-01]],\n",
       "\n",
       "         [[-9.1661e-01,  3.1951e-01, -2.6684e-01,  ...,  1.9626e-01,\n",
       "           -2.6724e-02, -5.4474e-01],\n",
       "          [-6.2846e-02,  1.2405e-01, -5.4855e-01,  ...,  1.4431e-01,\n",
       "           -2.9060e-01,  3.8806e-01],\n",
       "          [ 5.9608e-01, -6.5321e-01,  4.8228e-01,  ..., -4.6664e-01,\n",
       "            7.1481e-01, -1.7900e-01],\n",
       "          ...,\n",
       "          [ 1.8421e-01, -3.4658e-01,  5.2144e-01,  ..., -6.7280e-01,\n",
       "           -5.2645e-01, -2.6381e-01],\n",
       "          [ 7.4676e-01, -1.1772e-03, -2.8818e-01,  ...,  2.8830e-01,\n",
       "           -6.1454e-01,  6.6178e-01],\n",
       "          [ 3.1325e-01,  3.5814e-01, -5.8265e-01,  ..., -8.4492e-01,\n",
       "            3.9832e-01, -4.6640e-01]],\n",
       "\n",
       "         [[-1.2564e+00,  5.2829e-01,  6.4594e-01,  ...,  1.0891e+00,\n",
       "           -2.1399e-01,  4.3927e-01],\n",
       "          [-1.9281e-01,  3.0268e-01,  4.8179e-02,  ..., -6.0727e-01,\n",
       "           -3.6303e-01,  9.3197e-01],\n",
       "          [-5.3937e-01,  8.3248e-01, -1.5432e+00,  ..., -7.5939e-01,\n",
       "           -8.0075e-01,  1.1551e+00],\n",
       "          ...,\n",
       "          [ 2.6566e-01, -4.3494e-01, -7.9209e-01,  ..., -6.0323e-01,\n",
       "            3.5956e-02, -3.7404e-01],\n",
       "          [ 6.8276e-01, -7.2124e-01,  1.4289e-01,  ...,  7.2798e-01,\n",
       "           -1.1067e-02, -1.4575e-01],\n",
       "          [-2.8725e-01, -2.7125e-01, -6.5369e-01,  ..., -2.9213e-01,\n",
       "            4.4500e-01,  3.4721e-01]],\n",
       "\n",
       "         [[ 1.6973e-01, -1.6527e-01, -1.3691e+00,  ..., -7.0884e-01,\n",
       "           -2.3430e-01, -8.8984e-02],\n",
       "          [ 5.5845e-01, -5.0497e-01,  1.2248e+00,  ...,  1.6102e-01,\n",
       "            1.5331e+00, -4.9753e-01],\n",
       "          [ 4.3645e-01,  7.4671e-01, -2.0731e-01,  ...,  7.5144e-02,\n",
       "            7.3491e-01, -1.2837e-01],\n",
       "          ...,\n",
       "          [ 2.6913e-02,  7.2456e-03,  8.6957e-01,  ...,  1.0059e-01,\n",
       "            8.2898e-01,  7.7246e-01],\n",
       "          [ 2.9858e-01,  6.2858e-01, -4.8623e-01,  ...,  1.5576e-01,\n",
       "            4.5640e-02,  6.8074e-01],\n",
       "          [ 9.1136e-02, -6.5292e-02,  7.0566e-01,  ..., -4.6682e-01,\n",
       "            4.4166e-01, -1.9144e-01]]]], grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_3 = torch.nn.Conv2d(in_channels=3, out_channels=6,kernel_size=3, stride=1, padding=0, dilation=1, groups=1,bias=True, padding_mode=\"zeros\")\n",
    "output_3_1 = layer_3(Input)\n",
    "output_3_1                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w, b, conv_param):\n",
    "    out = None\n",
    "    padding = torch.nn.functional.pad\n",
    "    pad = conv_param['pad']\n",
    "    stride = conv_param['stride']\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape\n",
    "  \n",
    "    H_out = 1 + (H + 2 * pad - HH) // stride\n",
    "    W_out = 1 + (W + 2 * pad - WW) // stride\n",
    "    out = torch.zeros((N, F, H_out, W_out), device = x.device, dtype= x.dtype)\n",
    "  \n",
    "    x_pad = padding(x, (pad, pad, pad, pad), mode='constant', value=0) \n",
    "    for image in range(N): # each image\n",
    "        for flr in range(F): # for each filter\n",
    "            for i in range(H_out): # row\n",
    "                for j in range(W_out): # column\n",
    "                    out[image, flr, i, j] = torch.sum(x_pad[image, : , i*stride:i*stride+HH, j*stride:j*stride+WW] * w[flr, :, :, :]) + b[flr]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.7203e-01, -4.4504e-01,  2.1526e-01,  ...,  9.4919e-01,\n",
       "           -1.0656e-01, -5.6796e-01],\n",
       "          [-6.9558e-01,  4.4238e-01,  3.1154e-01,  ...,  8.8952e-01,\n",
       "           -3.4418e-01,  4.8535e-01],\n",
       "          [ 1.2032e+00, -3.5157e-01,  1.1570e-02,  ...,  4.8008e-01,\n",
       "            8.7856e-02, -4.4224e-01],\n",
       "          ...,\n",
       "          [-5.6077e-01, -3.2963e-01, -4.2985e-01,  ..., -1.0816e-01,\n",
       "           -2.6410e-01, -2.7346e-01],\n",
       "          [-2.4182e-02,  8.9218e-02, -1.4849e-01,  ...,  2.1303e-01,\n",
       "            2.9281e-03, -1.5736e-01],\n",
       "          [ 2.4689e-01,  1.0195e-01,  6.4096e-01,  ...,  3.6735e-01,\n",
       "           -4.6341e-01, -5.6703e-01]],\n",
       "\n",
       "         [[-4.1867e-01,  1.6466e-01, -5.7732e-03,  ...,  2.0410e-01,\n",
       "           -2.3797e-01,  1.3518e-01],\n",
       "          [ 3.2239e-01,  8.8653e-01,  4.9060e-01,  ...,  1.1738e+00,\n",
       "            1.8581e-01,  1.0463e-01],\n",
       "          [ 1.4067e-01, -6.8316e-01,  7.2514e-01,  ...,  1.3588e-01,\n",
       "            7.7709e-01, -3.8446e-01],\n",
       "          ...,\n",
       "          [-1.0492e-01,  2.5560e-01, -4.7244e-01,  ...,  4.5675e-01,\n",
       "            1.5188e-01,  2.3270e-01],\n",
       "          [ 2.0977e-01,  2.5171e-01, -7.7332e-01,  ..., -1.8220e-01,\n",
       "           -1.3236e-01,  9.9698e-01],\n",
       "          [ 6.3577e-01,  2.7215e-01,  7.9916e-01,  ...,  2.6645e-01,\n",
       "           -3.6362e-01, -6.3408e-01]],\n",
       "\n",
       "         [[-2.8971e-01,  2.1798e-01,  2.9415e-01,  ...,  5.0401e-01,\n",
       "           -1.1539e+00,  2.9358e-01],\n",
       "          [-2.8366e-01,  9.2011e-01, -5.4006e-01,  ...,  4.3700e-01,\n",
       "           -7.3780e-01,  2.2404e-01],\n",
       "          [ 2.0314e-01, -7.8640e-01,  7.0324e-01,  ...,  7.9478e-02,\n",
       "           -1.2091e-01, -3.8622e-01],\n",
       "          ...,\n",
       "          [ 6.0303e-02,  2.9337e-01,  6.2083e-02,  ..., -4.6981e-03,\n",
       "            4.3894e-01,  3.1941e-01],\n",
       "          [ 1.4782e-01,  1.3193e-01,  3.2466e-02,  ...,  4.7630e-03,\n",
       "           -2.4785e-01,  3.8520e-01],\n",
       "          [ 1.4039e+00, -5.6947e-03,  9.7006e-02,  ...,  2.7574e-01,\n",
       "            8.0594e-02,  5.7700e-01]],\n",
       "\n",
       "         [[-9.1661e-01,  3.1951e-01, -2.6684e-01,  ...,  1.9626e-01,\n",
       "           -2.6724e-02, -5.4474e-01],\n",
       "          [-6.2846e-02,  1.2405e-01, -5.4855e-01,  ...,  1.4431e-01,\n",
       "           -2.9060e-01,  3.8806e-01],\n",
       "          [ 5.9608e-01, -6.5321e-01,  4.8228e-01,  ..., -4.6664e-01,\n",
       "            7.1481e-01, -1.7900e-01],\n",
       "          ...,\n",
       "          [ 1.8421e-01, -3.4658e-01,  5.2144e-01,  ..., -6.7280e-01,\n",
       "           -5.2645e-01, -2.6381e-01],\n",
       "          [ 7.4676e-01, -1.1772e-03, -2.8818e-01,  ...,  2.8830e-01,\n",
       "           -6.1454e-01,  6.6178e-01],\n",
       "          [ 3.1325e-01,  3.5814e-01, -5.8265e-01,  ..., -8.4492e-01,\n",
       "            3.9832e-01, -4.6640e-01]],\n",
       "\n",
       "         [[-1.2564e+00,  5.2829e-01,  6.4594e-01,  ...,  1.0891e+00,\n",
       "           -2.1399e-01,  4.3927e-01],\n",
       "          [-1.9281e-01,  3.0268e-01,  4.8179e-02,  ..., -6.0727e-01,\n",
       "           -3.6303e-01,  9.3197e-01],\n",
       "          [-5.3937e-01,  8.3248e-01, -1.5432e+00,  ..., -7.5939e-01,\n",
       "           -8.0075e-01,  1.1551e+00],\n",
       "          ...,\n",
       "          [ 2.6566e-01, -4.3494e-01, -7.9209e-01,  ..., -6.0323e-01,\n",
       "            3.5956e-02, -3.7404e-01],\n",
       "          [ 6.8276e-01, -7.2124e-01,  1.4289e-01,  ...,  7.2798e-01,\n",
       "           -1.1067e-02, -1.4575e-01],\n",
       "          [-2.8725e-01, -2.7125e-01, -6.5369e-01,  ..., -2.9213e-01,\n",
       "            4.4500e-01,  3.4721e-01]],\n",
       "\n",
       "         [[ 1.6973e-01, -1.6527e-01, -1.3691e+00,  ..., -7.0884e-01,\n",
       "           -2.3430e-01, -8.8984e-02],\n",
       "          [ 5.5845e-01, -5.0497e-01,  1.2248e+00,  ...,  1.6102e-01,\n",
       "            1.5331e+00, -4.9753e-01],\n",
       "          [ 4.3645e-01,  7.4671e-01, -2.0731e-01,  ...,  7.5144e-02,\n",
       "            7.3491e-01, -1.2837e-01],\n",
       "          ...,\n",
       "          [ 2.6913e-02,  7.2456e-03,  8.6957e-01,  ...,  1.0059e-01,\n",
       "            8.2898e-01,  7.7246e-01],\n",
       "          [ 2.9858e-01,  6.2858e-01, -4.8623e-01,  ...,  1.5576e-01,\n",
       "            4.5640e-02,  6.8074e-01],\n",
       "          [ 9.1136e-02, -6.5292e-02,  7.0566e-01,  ..., -4.6682e-01,\n",
       "            4.4166e-01, -1.9143e-01]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_param = {'stride': 1, 'pad': 0}\n",
    "output_3_1_ = conv2d(Input, layer_3.weight, layer_3.bias, conv_param)\n",
    "output_3_1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1442e-15, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_3_1 = torch.nn.functional.mse_loss(output_3_1,output_3_1_)\n",
    "error_3_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.2649e-01,  2.0261e-01,  1.1391e-01,  ...,  1.3773e-01,\n",
       "            6.1435e-01, -8.8689e-01],\n",
       "          [-5.2798e-01,  9.7485e-02, -5.7463e-02,  ...,  5.3853e-01,\n",
       "            3.8538e-01, -4.6062e-01],\n",
       "          [ 3.2571e-01,  6.9098e-01, -5.2618e-01,  ..., -1.2193e-01,\n",
       "           -6.2236e-01, -5.9790e-01],\n",
       "          ...,\n",
       "          [-4.2108e-01,  6.6336e-01, -3.1995e-01,  ..., -3.5456e-01,\n",
       "           -4.8147e-01,  4.6441e-01],\n",
       "          [-2.1431e-01,  5.7067e-02,  1.4685e-01,  ...,  3.4145e-02,\n",
       "            4.8186e-01,  6.5116e-01],\n",
       "          [-2.4994e-01,  5.0221e-01, -1.9064e-01,  ..., -2.7203e-02,\n",
       "            1.0383e+00, -4.9113e-01]],\n",
       "\n",
       "         [[ 5.6631e-01, -4.0139e-02, -8.1993e-01,  ...,  6.7218e-01,\n",
       "            2.4324e-01, -8.6569e-01],\n",
       "          [ 7.9102e-02,  1.1307e+00,  2.7271e-01,  ...,  4.3627e-01,\n",
       "           -9.5368e-01, -1.0314e-01],\n",
       "          [-4.0247e-01, -1.3317e-01, -1.0286e-01,  ...,  3.6873e-01,\n",
       "           -3.4189e-01,  4.0420e-01],\n",
       "          ...,\n",
       "          [ 8.0091e-01, -3.0926e-01, -9.6219e-02,  ..., -1.9286e-01,\n",
       "           -5.9465e-01, -3.6664e-01],\n",
       "          [ 1.9880e+00,  6.7232e-01, -2.4842e-01,  ...,  4.8863e-01,\n",
       "            9.3766e-01, -2.3481e-01],\n",
       "          [ 5.7378e-01,  4.8218e-01, -1.3416e-01,  ...,  4.7675e-01,\n",
       "           -5.0172e-01, -1.5148e-01]],\n",
       "\n",
       "         [[ 3.0140e-01,  1.8076e-01,  1.0917e+00,  ..., -4.2703e-01,\n",
       "           -1.4618e+00, -4.6876e-01],\n",
       "          [-3.0007e-01, -1.1838e+00, -1.1501e+00,  ..., -9.5124e-02,\n",
       "           -3.2232e-01, -7.1047e-01],\n",
       "          [ 5.2594e-01,  4.8210e-01, -1.6948e-01,  ..., -1.2315e-01,\n",
       "            3.0027e-01,  2.0940e-01],\n",
       "          ...,\n",
       "          [-1.7954e-02, -3.3875e-01,  1.6980e-03,  ...,  3.1127e-01,\n",
       "            5.3828e-01, -8.2177e-01],\n",
       "          [ 2.0047e-01, -4.3946e-01, -2.7512e-01,  ...,  4.0341e-01,\n",
       "           -1.0021e+00, -9.1083e-01],\n",
       "          [ 3.3033e-01,  2.7479e-01,  1.4379e-01,  ...,  5.6653e-01,\n",
       "           -8.5605e-01,  4.7829e-01]],\n",
       "\n",
       "         [[-6.0071e-01, -5.2629e-01,  2.3231e-01,  ..., -5.9928e-01,\n",
       "           -2.2568e-01,  1.9206e-02],\n",
       "          [ 1.5309e-01, -5.2069e-01, -4.7179e-01,  ..., -5.1109e-01,\n",
       "           -1.5470e-03, -5.2107e-01],\n",
       "          [ 2.8443e-01, -2.0786e-01,  8.0102e-01,  ..., -1.9833e-01,\n",
       "           -3.6733e-01, -2.6632e-01],\n",
       "          ...,\n",
       "          [-2.8153e-01, -7.1084e-02,  9.6518e-01,  ...,  4.4831e-01,\n",
       "            2.4633e-01,  1.9441e-01],\n",
       "          [-1.1995e+00, -3.2471e-01,  1.1830e+00,  ..., -4.6744e-01,\n",
       "           -4.8905e-01, -8.7638e-02],\n",
       "          [ 1.4681e-01, -1.4774e-01, -9.3463e-02,  ...,  7.1322e-02,\n",
       "            1.1472e-01, -5.5999e-01]],\n",
       "\n",
       "         [[ 9.1031e-01,  5.1331e-01,  7.1155e-01,  ..., -1.0383e-01,\n",
       "           -6.4871e-01,  1.0527e-01],\n",
       "          [-9.2679e-01, -3.6954e-01,  7.5523e-01,  ..., -1.7341e-01,\n",
       "           -2.4152e-01, -4.2627e-01],\n",
       "          [ 5.9567e-01, -1.2408e+00, -5.6483e-01,  ...,  2.7504e-01,\n",
       "            1.5572e-01,  5.4080e-01],\n",
       "          ...,\n",
       "          [ 4.7731e-01,  5.5174e-01, -1.6483e-01,  ...,  2.0513e-01,\n",
       "           -6.5435e-01, -3.4430e-01],\n",
       "          [ 5.0674e-01, -2.7262e-02, -2.9780e-02,  ...,  2.0693e-01,\n",
       "            9.1405e-02, -4.4954e-01],\n",
       "          [-7.3256e-01,  1.0962e+00,  4.4802e-01,  ..., -1.5616e-01,\n",
       "           -2.2680e-01,  4.0916e-01]],\n",
       "\n",
       "         [[-3.0152e-01,  9.6622e-01, -1.0189e-01,  ...,  1.1298e+00,\n",
       "            5.0974e-01, -5.6760e-01],\n",
       "          [-1.3588e-01, -7.8095e-01, -4.9667e-01,  ...,  7.1553e-01,\n",
       "            4.4540e-01,  4.8479e-02],\n",
       "          [ 3.1957e-01,  4.1031e-01, -6.4852e-01,  ..., -6.5196e-01,\n",
       "           -2.8032e-01,  1.3013e+00],\n",
       "          ...,\n",
       "          [ 2.2303e-01,  4.0483e-01,  2.1270e-01,  ...,  8.9534e-01,\n",
       "            2.8931e-01, -2.7898e-01],\n",
       "          [ 3.1263e-01,  1.6644e-01, -7.3970e-02,  ...,  1.2885e-01,\n",
       "            3.7311e-01, -2.5014e-01],\n",
       "          [ 3.3671e-01, -1.3737e-01, -6.3772e-01,  ..., -1.9324e-01,\n",
       "           -3.9228e-01,  3.0381e-01]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_3_ = torch.nn.Conv2d(in_channels=3, out_channels=6,kernel_size=5, stride=2, padding=0, dilation=1, groups=1,bias=True, padding_mode=\"zeros\")\n",
    "output_3_2 = layer_3_(Input)\n",
    "output_3_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.2649e-01,  2.0261e-01,  1.1391e-01,  ...,  1.3773e-01,\n",
       "            6.1435e-01, -8.8689e-01],\n",
       "          [-5.2798e-01,  9.7485e-02, -5.7463e-02,  ...,  5.3853e-01,\n",
       "            3.8538e-01, -4.6062e-01],\n",
       "          [ 3.2571e-01,  6.9098e-01, -5.2618e-01,  ..., -1.2193e-01,\n",
       "           -6.2236e-01, -5.9790e-01],\n",
       "          ...,\n",
       "          [-4.2108e-01,  6.6335e-01, -3.1995e-01,  ..., -3.5456e-01,\n",
       "           -4.8147e-01,  4.6441e-01],\n",
       "          [-2.1431e-01,  5.7067e-02,  1.4685e-01,  ...,  3.4145e-02,\n",
       "            4.8186e-01,  6.5116e-01],\n",
       "          [-2.4994e-01,  5.0221e-01, -1.9064e-01,  ..., -2.7203e-02,\n",
       "            1.0383e+00, -4.9113e-01]],\n",
       "\n",
       "         [[ 5.6631e-01, -4.0139e-02, -8.1993e-01,  ...,  6.7218e-01,\n",
       "            2.4324e-01, -8.6569e-01],\n",
       "          [ 7.9102e-02,  1.1307e+00,  2.7271e-01,  ...,  4.3627e-01,\n",
       "           -9.5368e-01, -1.0314e-01],\n",
       "          [-4.0247e-01, -1.3317e-01, -1.0286e-01,  ...,  3.6873e-01,\n",
       "           -3.4189e-01,  4.0420e-01],\n",
       "          ...,\n",
       "          [ 8.0091e-01, -3.0926e-01, -9.6219e-02,  ..., -1.9286e-01,\n",
       "           -5.9465e-01, -3.6664e-01],\n",
       "          [ 1.9880e+00,  6.7232e-01, -2.4842e-01,  ...,  4.8863e-01,\n",
       "            9.3766e-01, -2.3481e-01],\n",
       "          [ 5.7378e-01,  4.8218e-01, -1.3416e-01,  ...,  4.7675e-01,\n",
       "           -5.0172e-01, -1.5148e-01]],\n",
       "\n",
       "         [[ 3.0140e-01,  1.8076e-01,  1.0917e+00,  ..., -4.2703e-01,\n",
       "           -1.4618e+00, -4.6876e-01],\n",
       "          [-3.0007e-01, -1.1838e+00, -1.1501e+00,  ..., -9.5124e-02,\n",
       "           -3.2232e-01, -7.1047e-01],\n",
       "          [ 5.2594e-01,  4.8210e-01, -1.6948e-01,  ..., -1.2315e-01,\n",
       "            3.0027e-01,  2.0940e-01],\n",
       "          ...,\n",
       "          [-1.7954e-02, -3.3875e-01,  1.6980e-03,  ...,  3.1127e-01,\n",
       "            5.3828e-01, -8.2177e-01],\n",
       "          [ 2.0047e-01, -4.3946e-01, -2.7512e-01,  ...,  4.0341e-01,\n",
       "           -1.0021e+00, -9.1083e-01],\n",
       "          [ 3.3033e-01,  2.7479e-01,  1.4379e-01,  ...,  5.6653e-01,\n",
       "           -8.5605e-01,  4.7829e-01]],\n",
       "\n",
       "         [[-6.0071e-01, -5.2629e-01,  2.3231e-01,  ..., -5.9928e-01,\n",
       "           -2.2568e-01,  1.9206e-02],\n",
       "          [ 1.5309e-01, -5.2069e-01, -4.7179e-01,  ..., -5.1109e-01,\n",
       "           -1.5470e-03, -5.2107e-01],\n",
       "          [ 2.8443e-01, -2.0786e-01,  8.0102e-01,  ..., -1.9833e-01,\n",
       "           -3.6733e-01, -2.6632e-01],\n",
       "          ...,\n",
       "          [-2.8153e-01, -7.1085e-02,  9.6518e-01,  ...,  4.4831e-01,\n",
       "            2.4633e-01,  1.9441e-01],\n",
       "          [-1.1995e+00, -3.2471e-01,  1.1830e+00,  ..., -4.6744e-01,\n",
       "           -4.8905e-01, -8.7638e-02],\n",
       "          [ 1.4681e-01, -1.4774e-01, -9.3463e-02,  ...,  7.1321e-02,\n",
       "            1.1472e-01, -5.5999e-01]],\n",
       "\n",
       "         [[ 9.1031e-01,  5.1331e-01,  7.1155e-01,  ..., -1.0383e-01,\n",
       "           -6.4871e-01,  1.0527e-01],\n",
       "          [-9.2679e-01, -3.6954e-01,  7.5523e-01,  ..., -1.7341e-01,\n",
       "           -2.4152e-01, -4.2627e-01],\n",
       "          [ 5.9567e-01, -1.2408e+00, -5.6483e-01,  ...,  2.7504e-01,\n",
       "            1.5572e-01,  5.4080e-01],\n",
       "          ...,\n",
       "          [ 4.7731e-01,  5.5174e-01, -1.6483e-01,  ...,  2.0513e-01,\n",
       "           -6.5435e-01, -3.4430e-01],\n",
       "          [ 5.0674e-01, -2.7262e-02, -2.9780e-02,  ...,  2.0693e-01,\n",
       "            9.1405e-02, -4.4954e-01],\n",
       "          [-7.3256e-01,  1.0962e+00,  4.4802e-01,  ..., -1.5616e-01,\n",
       "           -2.2680e-01,  4.0916e-01]],\n",
       "\n",
       "         [[-3.0152e-01,  9.6622e-01, -1.0189e-01,  ...,  1.1298e+00,\n",
       "            5.0974e-01, -5.6760e-01],\n",
       "          [-1.3588e-01, -7.8095e-01, -4.9667e-01,  ...,  7.1553e-01,\n",
       "            4.4540e-01,  4.8479e-02],\n",
       "          [ 3.1957e-01,  4.1031e-01, -6.4852e-01,  ..., -6.5195e-01,\n",
       "           -2.8032e-01,  1.3013e+00],\n",
       "          ...,\n",
       "          [ 2.2303e-01,  4.0483e-01,  2.1270e-01,  ...,  8.9534e-01,\n",
       "            2.8931e-01, -2.7898e-01],\n",
       "          [ 3.1263e-01,  1.6644e-01, -7.3970e-02,  ...,  1.2885e-01,\n",
       "            3.7311e-01, -2.5014e-01],\n",
       "          [ 3.3671e-01, -1.3737e-01, -6.3772e-01,  ..., -1.9324e-01,\n",
       "           -3.9228e-01,  3.0381e-01]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_param = {'stride': 2, 'pad': 0}\n",
    "output_3_2_ = conv2d(Input, layer_3_.weight, layer_3_.bias, conv_param)\n",
    "output_3_2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.2051e-15, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_3_2 = torch.nn.functional.mse_loss(output_3_2,output_3_2_)\n",
    "error_3_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4: torch.nn.ConvTranspose2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0504,  0.5800,  0.2070,  ...,  0.1275,  0.0638,  0.1048],\n",
       "          [-0.0216,  0.4826, -0.2618,  ...,  0.4198,  0.0998,  0.1133],\n",
       "          [-0.3666,  0.9423, -0.2220,  ..., -0.1946, -0.0681, -0.0588],\n",
       "          ...,\n",
       "          [-0.0938,  0.5015,  0.4664,  ...,  0.0483,  0.1389, -0.3200],\n",
       "          [ 0.3685,  0.3206, -0.4306,  ...,  0.3167, -0.3360,  0.2729],\n",
       "          [ 0.1233, -0.2338,  0.3841,  ..., -0.0300,  0.4937,  0.0741]],\n",
       "\n",
       "         [[ 0.0635,  0.2854, -0.0904,  ...,  0.5334,  0.2433,  0.2862],\n",
       "          [-0.0519, -0.3673, -0.6038,  ...,  0.3755,  0.1489,  0.2816],\n",
       "          [ 0.1492,  0.0312,  0.7939,  ...,  0.0651,  0.2043,  0.1165],\n",
       "          ...,\n",
       "          [ 0.4137, -0.3179, -0.4402,  ..., -0.4524, -0.2799, -0.0806],\n",
       "          [-0.0829, -0.0312,  0.8366,  ...,  0.3287,  0.6308,  0.2726],\n",
       "          [ 0.1903,  0.2443, -0.1163,  ...,  0.3826, -0.0642,  0.0931]],\n",
       "\n",
       "         [[ 0.0629,  0.1590,  0.2495,  ...,  0.0082,  0.3712,  0.0030],\n",
       "          [ 0.4158, -0.2845, -0.0636,  ...,  0.0774,  0.0778,  0.0020],\n",
       "          [-0.3171,  0.5169, -0.3217,  ..., -0.2425, -0.0686,  0.2423],\n",
       "          ...,\n",
       "          [ 0.1595, -0.0540,  0.7734,  ...,  0.0224,  0.1414,  0.1268],\n",
       "          [-0.4657, -0.0517, -0.4957,  ...,  0.1386, -0.1510, -0.3616],\n",
       "          [ 0.1781, -0.1034, -0.0022,  ...,  0.1225,  0.1696,  0.1470]],\n",
       "\n",
       "         [[ 0.0733, -0.1917, -0.1774,  ..., -0.2481,  0.0509, -0.2348],\n",
       "          [ 0.3114, -0.3793,  0.6658,  ..., -0.1266, -0.1756, -0.2001],\n",
       "          [ 0.1327, -0.2691,  0.0280,  ...,  0.5572,  0.5411,  0.1902],\n",
       "          ...,\n",
       "          [ 0.1380,  0.2297,  0.4841,  ...,  0.0246,  0.3256,  0.6217],\n",
       "          [ 0.2260,  0.2929,  0.0240,  ..., -0.2479, -0.1367, -0.1618],\n",
       "          [-0.3123,  0.0870, -0.2333,  ...,  0.4060, -0.0239,  0.0476]]]],\n",
       "       grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_4 = torch.nn.ConvTranspose2d(in_channels=3, out_channels=4,kernel_size=3, stride=1, padding=0, output_padding=0,groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "output_4 = layer_4(Input)\n",
    "output_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(x, weight, bias, channel):\n",
    "    h = weight.shape[2]\n",
    "    w = weight.shape[3]\n",
    "    out = torch.zeros((1, x.shape[1] + h - 1, x.shape[2] + w - 1))\n",
    "    for k in range(x.shape[0]):\n",
    "        for i in range(x.shape[1]):\n",
    "            for j in range(x.shape[2]):\n",
    "                out[0,i:i + h, j:j + w] += x[k, i, j] * weight[k][channel]\n",
    "    out += bias[channel]\n",
    "    return out\n",
    "def trans_conv(x, weight, bias, out_channel):\n",
    "    result = []\n",
    "    \n",
    "    for i in range(out_channel):\n",
    "        out = trans(x, weight, bias, i)\n",
    "        result.append(out[0])\n",
    "    return torch.stack(result,dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0504,  0.5800,  0.2070,  ...,  0.1275,  0.0638,  0.1048],\n",
       "         [-0.0216,  0.4826, -0.2618,  ...,  0.4198,  0.0998,  0.1133],\n",
       "         [-0.3666,  0.9423, -0.2220,  ..., -0.1946, -0.0681, -0.0588],\n",
       "         ...,\n",
       "         [-0.0938,  0.5015,  0.4664,  ...,  0.0483,  0.1389, -0.3200],\n",
       "         [ 0.3685,  0.3206, -0.4306,  ...,  0.3167, -0.3360,  0.2729],\n",
       "         [ 0.1233, -0.2338,  0.3841,  ..., -0.0300,  0.4937,  0.0741]],\n",
       "\n",
       "        [[ 0.0635,  0.2854, -0.0904,  ...,  0.5334,  0.2433,  0.2862],\n",
       "         [-0.0519, -0.3673, -0.6038,  ...,  0.3755,  0.1489,  0.2816],\n",
       "         [ 0.1492,  0.0312,  0.7939,  ...,  0.0651,  0.2043,  0.1165],\n",
       "         ...,\n",
       "         [ 0.4137, -0.3179, -0.4402,  ..., -0.4524, -0.2799, -0.0806],\n",
       "         [-0.0829, -0.0312,  0.8366,  ...,  0.3287,  0.6308,  0.2726],\n",
       "         [ 0.1903,  0.2443, -0.1163,  ...,  0.3826, -0.0642,  0.0931]],\n",
       "\n",
       "        [[ 0.0629,  0.1590,  0.2495,  ...,  0.0082,  0.3712,  0.0030],\n",
       "         [ 0.4158, -0.2845, -0.0636,  ...,  0.0774,  0.0778,  0.0020],\n",
       "         [-0.3171,  0.5169, -0.3217,  ..., -0.2425, -0.0686,  0.2423],\n",
       "         ...,\n",
       "         [ 0.1595, -0.0540,  0.7734,  ...,  0.0224,  0.1414,  0.1268],\n",
       "         [-0.4657, -0.0517, -0.4957,  ...,  0.1386, -0.1510, -0.3616],\n",
       "         [ 0.1781, -0.1034, -0.0022,  ...,  0.1225,  0.1696,  0.1470]],\n",
       "\n",
       "        [[ 0.0733, -0.1917, -0.1774,  ..., -0.2481,  0.0509, -0.2348],\n",
       "         [ 0.3114, -0.3793,  0.6658,  ..., -0.1266, -0.1756, -0.2001],\n",
       "         [ 0.1327, -0.2691,  0.0280,  ...,  0.5572,  0.5411,  0.1902],\n",
       "         ...,\n",
       "         [ 0.1380,  0.2297,  0.4841,  ...,  0.0246,  0.3256,  0.6217],\n",
       "         [ 0.2260,  0.2929,  0.0240,  ..., -0.2479, -0.1367, -0.1618],\n",
       "         [-0.3123,  0.0870, -0.2333,  ...,  0.4060, -0.0239,  0.0476]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_4_ = trans_conv(Input[0], layer_4.weight, layer_4.bias, layer_4.out_channels)\n",
    "output_4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7919e-15, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_4 = torch.nn.functional.mse_loss(output_4[0],output_4_)\n",
    "error_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5: torch.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1981, -0.4645, -0.1567,  ..., -0.5632,  0.7777, -0.7101])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_5 = torch.flatten(Input, start_dim=0, end_dim=-1)\n",
    "output_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Flatten(inp):\n",
    "    flatten_list = []\n",
    "    for i in inp:\n",
    "        for j in i:\n",
    "            for h in j:  \n",
    "                for w in h:\n",
    "                    flatten_list.append(w)\n",
    "    return torch.tensor(np.array(flatten_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1981, -0.4645, -0.1567,  ..., -0.5632,  0.7777, -0.7101])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_5_ = Flatten(Input)\n",
    "output_5_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_5 = torch.nn.functional.mse_loss(output_5,output_5_)\n",
    "error_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 6: torch.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9001, 0.3859, 0.4609,  ..., 0.5886, 0.6243, 0.6562],\n",
       "          [0.3362, 0.1918, 0.3846,  ..., 0.1732, 0.4367, 0.4199],\n",
       "          [0.7949, 0.5309, 0.3814,  ..., 0.2634, 0.1012, 0.4717],\n",
       "          ...,\n",
       "          [0.4157, 0.6198, 0.4486,  ..., 0.3626, 0.6608, 0.5704],\n",
       "          [0.8599, 0.7185, 0.3860,  ..., 0.4047, 0.6308, 0.7454],\n",
       "          [0.2668, 0.4691, 0.7344,  ..., 0.3976, 0.2483, 0.3290]],\n",
       "\n",
       "         [[0.3700, 0.5553, 0.8375,  ..., 0.1029, 0.1663, 0.1256],\n",
       "          [0.6464, 0.5504, 0.5541,  ..., 0.7307, 0.6407, 0.4997],\n",
       "          [0.3059, 0.7610, 0.2945,  ..., 0.6374, 0.3761, 0.5717],\n",
       "          ...,\n",
       "          [0.2005, 0.3660, 0.5228,  ..., 0.4151, 0.4547, 0.2259],\n",
       "          [0.4966, 0.2808, 0.5235,  ..., 0.6007, 0.3863, 0.8238],\n",
       "          [0.6620, 0.3690, 0.4866,  ..., 0.1231, 0.4248, 0.3439]],\n",
       "\n",
       "         [[0.3575, 0.5674, 0.4181,  ..., 0.5938, 0.3809, 0.6525],\n",
       "          [0.1615, 0.3495, 0.1877,  ..., 0.6947, 0.2881, 0.4380],\n",
       "          [0.6457, 0.4526, 0.5775,  ..., 0.7009, 0.4175, 0.3242],\n",
       "          ...,\n",
       "          [0.3941, 0.2353, 0.3103,  ..., 0.5055, 0.3860, 0.5169],\n",
       "          [0.1129, 0.5568, 0.5574,  ..., 0.4623, 0.1338, 0.5655],\n",
       "          [0.7480, 0.5983, 0.5217,  ..., 0.3628, 0.6852, 0.3296]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_6 = torch.sigmoid(Input, out=None)\n",
    "output_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9001, 0.3859, 0.4609,  ..., 0.5886, 0.6243, 0.6562],\n",
       "          [0.3362, 0.1918, 0.3846,  ..., 0.1732, 0.4367, 0.4199],\n",
       "          [0.7949, 0.5309, 0.3814,  ..., 0.2634, 0.1012, 0.4717],\n",
       "          ...,\n",
       "          [0.4157, 0.6198, 0.4486,  ..., 0.3626, 0.6608, 0.5704],\n",
       "          [0.8599, 0.7185, 0.3860,  ..., 0.4047, 0.6308, 0.7454],\n",
       "          [0.2668, 0.4691, 0.7344,  ..., 0.3976, 0.2483, 0.3290]],\n",
       "\n",
       "         [[0.3700, 0.5553, 0.8375,  ..., 0.1029, 0.1663, 0.1256],\n",
       "          [0.6464, 0.5504, 0.5541,  ..., 0.7307, 0.6407, 0.4997],\n",
       "          [0.3059, 0.7610, 0.2945,  ..., 0.6374, 0.3761, 0.5717],\n",
       "          ...,\n",
       "          [0.2005, 0.3660, 0.5228,  ..., 0.4151, 0.4547, 0.2259],\n",
       "          [0.4966, 0.2808, 0.5235,  ..., 0.6007, 0.3863, 0.8238],\n",
       "          [0.6620, 0.3690, 0.4866,  ..., 0.1231, 0.4248, 0.3439]],\n",
       "\n",
       "         [[0.3575, 0.5674, 0.4181,  ..., 0.5938, 0.3809, 0.6525],\n",
       "          [0.1615, 0.3495, 0.1877,  ..., 0.6947, 0.2881, 0.4380],\n",
       "          [0.6457, 0.4526, 0.5775,  ..., 0.7009, 0.4175, 0.3242],\n",
       "          ...,\n",
       "          [0.3941, 0.2353, 0.3103,  ..., 0.5055, 0.3860, 0.5169],\n",
       "          [0.1129, 0.5568, 0.5574,  ..., 0.4623, 0.1338, 0.5655],\n",
       "          [0.7480, 0.5983, 0.5217,  ..., 0.3628, 0.6852, 0.3296]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sigmoid (inp):\n",
    "    output = 1.0 / (1.0 + np.exp(-inp))\n",
    "    return output\n",
    "    \n",
    "output_6_ = Sigmoid (Input)\n",
    "output_6_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_6 = torch.nn.functional.mse_loss(output_6,output_6_)\n",
    "error_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 7: torchvision.ops.roi_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.1981, 1.9790, 1.6071, 2.0625, 1.0465, 0.8380, 2.3753, 1.8966],\n",
       "          [1.2296, 1.9685, 2.0244, 2.4132, 3.0291, 1.6265, 3.2492, 1.6545],\n",
       "          [2.0207, 1.6958, 1.8471, 0.8338, 3.0506, 3.1423, 3.2835, 1.3767],\n",
       "          [1.9030, 1.5254, 1.4021, 2.5892, 2.5467, 1.6599, 1.7575, 1.1418],\n",
       "          [2.1492, 1.5503, 1.4249, 1.8803, 1.7536, 2.6992, 1.2558, 2.2438],\n",
       "          [2.6675, 1.0331, 1.1781, 0.9944, 2.0451, 1.7235, 1.4303, 2.0411],\n",
       "          [1.2586, 1.7807, 2.4085, 2.0107, 2.3379, 1.0800, 1.9881, 1.4275],\n",
       "          [1.8143, 2.8771, 1.0929, 1.7023, 2.1186, 2.1242, 1.4403, 1.0744]],\n",
       "\n",
       "         [[1.6399, 1.8884, 0.8022, 1.3953, 1.4934, 2.7523, 1.5673, 0.9981],\n",
       "          [0.5793, 2.0730, 1.3050, 1.3257, 1.2001, 1.6155, 1.8762, 1.7314],\n",
       "          [1.0106, 2.4755, 1.1288, 1.7837, 2.3973, 1.2521, 1.4686, 2.0514],\n",
       "          [1.1400, 2.2882, 1.8141, 1.1265, 0.8046, 2.2316, 0.5494, 1.8949],\n",
       "          [1.8246, 2.2268, 2.5240, 1.5624, 2.8340, 2.0574, 1.7611, 1.0739],\n",
       "          [2.0119, 1.6254, 1.5081, 1.5990, 1.8153, 1.0256, 1.2933, 1.0968],\n",
       "          [2.0510, 1.2343, 1.5927, 1.4486, 2.1476, 2.3081, 1.7946, 1.5115],\n",
       "          [1.9908, 2.3769, 1.8231, 1.1723, 2.5051, 1.5626, 1.2167, 1.5426]],\n",
       "\n",
       "         [[1.8494, 2.0003, 1.1473, 1.9122, 1.9457, 1.7472, 1.8277, 1.7095],\n",
       "          [2.9181, 1.6197, 2.1732, 1.7555, 1.4949, 1.4206, 1.0118, 1.7447],\n",
       "          [2.8523, 1.6358, 1.7383, 1.8808, 1.5652, 0.9783, 1.4617, 2.1359],\n",
       "          [1.8340, 1.5285, 1.5184, 2.2951, 2.2391, 2.1326, 2.2947, 2.2230],\n",
       "          [1.5372, 1.1277, 1.6670, 2.1078, 1.1856, 1.0652, 1.3607, 1.9303],\n",
       "          [2.1606, 1.8158, 1.3275, 1.3923, 1.7321, 1.3867, 0.7740, 1.2590],\n",
       "          [1.6537, 0.9367, 2.4231, 1.3289, 2.4423, 1.2763, 1.7924, 1.4178],\n",
       "          [1.8620, 1.4183, 1.2417, 1.0636, 1.5514, 1.2928, 2.2285, 1.5565]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = torch.tensor([[0,0,0,31,31]]).float()\n",
    "output_7 = torchvision.ops.roi_pool(Input, box,output_size=(8,8))\n",
    "output_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roipool(x, boxes, output_size=(8,8)):\n",
    "    \n",
    "    roi_start_h = int(boxes[0][1])\n",
    "    roi_start_w = int(boxes[0][2])\n",
    "    roi_end_h = int(boxes[0][3])\n",
    "    roi_end_w = int(boxes[0][4])\n",
    "    roi_width = (roi_end_w - roi_start_w + 1)\n",
    "    roi_height = (roi_end_h - roi_start_h + 1)\n",
    "\n",
    "    bin_size_w = roi_width / 8\n",
    "    bin_size_h = roi_height / 8\n",
    "    \n",
    "    self_result = []\n",
    "    for k in range(x.shape[1]):\n",
    "        temp = []\n",
    "        for j in range(8):\n",
    "            sub_res = []\n",
    "            for i in range(8):\n",
    "                sub_res.append(x[..., int(0+bin_size_h*(j)):math.ceil(0+bin_size_h*(j+1)),\n",
    "                                     int(0+bin_size_w*(i)):math.ceil(0+bin_size_w*(i+1))][0][k].max())\n",
    "            temp.append(sub_res)\n",
    "        self_result.append(temp)\n",
    "    res=torch.Tensor(self_result)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1981, 1.9790, 1.6071, 2.0625, 1.0465, 0.8380, 2.3753, 1.8966],\n",
       "         [1.2296, 1.9685, 2.0244, 2.4132, 3.0291, 1.6265, 3.2492, 1.6545],\n",
       "         [2.0207, 1.6958, 1.8471, 0.8338, 3.0506, 3.1423, 3.2835, 1.3767],\n",
       "         [1.9030, 1.5254, 1.4021, 2.5892, 2.5467, 1.6599, 1.7575, 1.1418],\n",
       "         [2.1492, 1.5503, 1.4249, 1.8803, 1.7536, 2.6992, 1.2558, 2.2438],\n",
       "         [2.6675, 1.0331, 1.1781, 0.9944, 2.0451, 1.7235, 1.4303, 2.0411],\n",
       "         [1.2586, 1.7807, 2.4085, 2.0107, 2.3379, 1.0800, 1.9881, 1.4275],\n",
       "         [1.8143, 2.8771, 1.0929, 1.7023, 2.1186, 2.1242, 1.4403, 1.0744]],\n",
       "\n",
       "        [[1.6399, 1.8884, 0.8022, 1.3953, 1.4934, 2.7523, 1.5673, 0.9981],\n",
       "         [0.5793, 2.0730, 1.3050, 1.3257, 1.2001, 1.6155, 1.8762, 1.7314],\n",
       "         [1.0106, 2.4755, 1.1288, 1.7837, 2.3973, 1.2521, 1.4686, 2.0514],\n",
       "         [1.1400, 2.2882, 1.8141, 1.1265, 0.8046, 2.2316, 0.5494, 1.8949],\n",
       "         [1.8246, 2.2268, 2.5240, 1.5624, 2.8340, 2.0574, 1.7611, 1.0739],\n",
       "         [2.0119, 1.6254, 1.5081, 1.5990, 1.8153, 1.0256, 1.2933, 1.0968],\n",
       "         [2.0510, 1.2343, 1.5927, 1.4486, 2.1476, 2.3081, 1.7946, 1.5115],\n",
       "         [1.9908, 2.3769, 1.8231, 1.1723, 2.5051, 1.5626, 1.2167, 1.5426]],\n",
       "\n",
       "        [[1.8494, 2.0003, 1.1473, 1.9122, 1.9457, 1.7472, 1.8277, 1.7095],\n",
       "         [2.9181, 1.6197, 2.1732, 1.7555, 1.4949, 1.4206, 1.0118, 1.7447],\n",
       "         [2.8523, 1.6358, 1.7383, 1.8808, 1.5652, 0.9783, 1.4617, 2.1359],\n",
       "         [1.8340, 1.5285, 1.5184, 2.2951, 2.2391, 2.1326, 2.2947, 2.2230],\n",
       "         [1.5372, 1.1277, 1.6670, 2.1078, 1.1856, 1.0652, 1.3607, 1.9303],\n",
       "         [2.1606, 1.8158, 1.3275, 1.3923, 1.7321, 1.3867, 0.7740, 1.2590],\n",
       "         [1.6537, 0.9367, 2.4231, 1.3289, 2.4423, 1.2763, 1.7924, 1.4178],\n",
       "         [1.8620, 1.4183, 1.2417, 1.0636, 1.5514, 1.2928, 2.2285, 1.5565]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_7_ = roipool(Input, box, output_size=(8,8))\n",
    "output_7_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-eb177f28b4f7>:1: UserWarning: Using a target size (torch.Size([3, 8, 8])) that is different to the input size (torch.Size([1, 3, 8, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  error_7 = torch.nn.functional.mse_loss(output_7,output_7_)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_7 = torch.nn.functional.mse_loss(output_7,output_7_)\n",
    "error_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 8: torch.nn.functional.batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.4715e-01, -1.0356e+00, -8.1788e-01,  ..., -4.5378e-01,\n",
       "           -3.4808e-01, -2.4996e-01],\n",
       "          [-1.1880e+00, -1.7242e+00, -1.0394e+00,  ..., -1.8123e+00,\n",
       "           -8.8706e-01, -9.3564e-01],\n",
       "          [ 2.5101e-01, -6.1962e-01, -1.0490e+00,  ..., -1.4341e+00,\n",
       "           -2.2515e+00, -7.8734e-01],\n",
       "          ...,\n",
       "          [-9.4771e-01, -3.6150e-01, -8.5304e-01,  ..., -1.1061e+00,\n",
       "           -2.3564e-01, -5.0672e-01],\n",
       "          [ 5.7579e-01, -4.4478e-02, -1.0353e+00,  ..., -9.7996e-01,\n",
       "           -3.2826e-01,  5.2621e-02],\n",
       "          [-1.4219e+00, -7.9475e-01,  1.2240e-02,  ..., -1.0008e+00,\n",
       "           -1.4902e+00, -1.2112e+00]],\n",
       "\n",
       "         [[-1.0834e+00, -5.4995e-01,  4.5247e-01,  ..., -2.2382e+00,\n",
       "           -1.8470e+00, -2.0792e+00],\n",
       "          [-2.8049e-01, -5.6402e-01, -5.5360e-01,  ..., -1.3666e-03,\n",
       "           -2.9825e-01, -7.0809e-01],\n",
       "          [-1.2865e+00,  1.1202e-01, -1.3250e+00,  ..., -3.0829e-01,\n",
       "           -1.0649e+00, -5.0279e-01],\n",
       "          ...,\n",
       "          [-1.6853e+00, -1.0955e+00, -6.4249e-01,  ..., -9.4947e-01,\n",
       "           -8.3573e-01, -1.5778e+00],\n",
       "          [-7.1665e-01, -1.3721e+00, -6.4047e-01,  ..., -4.1819e-01,\n",
       "           -1.0344e+00,  3.8367e-01],\n",
       "          [-2.3163e-01, -1.0865e+00, -7.4498e-01,  ..., -2.0955e+00,\n",
       "           -9.2149e-01, -1.1640e+00]],\n",
       "\n",
       "         [[-1.1217e+00, -5.1537e-01, -9.4099e-01,  ..., -4.3875e-01,\n",
       "           -1.0507e+00, -2.6148e-01],\n",
       "          [-1.8716e+00, -1.1463e+00, -1.7432e+00,  ..., -1.2590e-01,\n",
       "           -1.3466e+00, -8.8341e-01],\n",
       "          [-2.8286e-01, -8.4167e-01, -4.8598e-01,  ..., -1.0491e-01,\n",
       "           -9.4246e-01, -1.2264e+00],\n",
       "          ...,\n",
       "          [-1.0114e+00, -1.5403e+00, -1.2718e+00,  ..., -6.9153e-01,\n",
       "           -1.0353e+00, -6.5931e-01],\n",
       "          [-2.1648e+00, -5.4565e-01, -5.4402e-01,  ..., -8.1402e-01,\n",
       "           -2.0280e+00, -5.2083e-01],\n",
       "          [ 6.2025e-02, -4.2551e-01, -6.4577e-01,  ..., -1.1053e+00,\n",
       "           -1.5719e-01, -1.2092e+00]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_mean = torch.zeros(3)+1\n",
    "running_var = torch.ones(3)*2\n",
    "output_8 = torch.nn.functional.batch_norm(Input, running_mean, running_var, weight=None, bias=None, training=False, momentum=0.1, eps=1e-05)\n",
    "output_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm(input, running_mean, running_var, momentum=0.1, eps=1e-05):\n",
    "    mean = running_mean\n",
    "    var = running_var\n",
    "    mean, var = mean[:,None,None],var[:,None,None]\n",
    "    \n",
    "    return (input-mean) / torch.sqrt(var+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.4715e-01, -1.0356e+00, -8.1788e-01,  ..., -4.5378e-01,\n",
       "           -3.4808e-01, -2.4996e-01],\n",
       "          [-1.1880e+00, -1.7242e+00, -1.0394e+00,  ..., -1.8123e+00,\n",
       "           -8.8706e-01, -9.3564e-01],\n",
       "          [ 2.5101e-01, -6.1962e-01, -1.0490e+00,  ..., -1.4341e+00,\n",
       "           -2.2515e+00, -7.8734e-01],\n",
       "          ...,\n",
       "          [-9.4771e-01, -3.6150e-01, -8.5304e-01,  ..., -1.1061e+00,\n",
       "           -2.3564e-01, -5.0672e-01],\n",
       "          [ 5.7579e-01, -4.4478e-02, -1.0353e+00,  ..., -9.7996e-01,\n",
       "           -3.2826e-01,  5.2621e-02],\n",
       "          [-1.4219e+00, -7.9475e-01,  1.2240e-02,  ..., -1.0008e+00,\n",
       "           -1.4902e+00, -1.2112e+00]],\n",
       "\n",
       "         [[-1.0834e+00, -5.4995e-01,  4.5247e-01,  ..., -2.2382e+00,\n",
       "           -1.8470e+00, -2.0792e+00],\n",
       "          [-2.8049e-01, -5.6402e-01, -5.5360e-01,  ..., -1.3666e-03,\n",
       "           -2.9825e-01, -7.0809e-01],\n",
       "          [-1.2865e+00,  1.1202e-01, -1.3250e+00,  ..., -3.0829e-01,\n",
       "           -1.0649e+00, -5.0279e-01],\n",
       "          ...,\n",
       "          [-1.6853e+00, -1.0955e+00, -6.4249e-01,  ..., -9.4947e-01,\n",
       "           -8.3573e-01, -1.5778e+00],\n",
       "          [-7.1665e-01, -1.3721e+00, -6.4047e-01,  ..., -4.1819e-01,\n",
       "           -1.0344e+00,  3.8367e-01],\n",
       "          [-2.3163e-01, -1.0865e+00, -7.4498e-01,  ..., -2.0955e+00,\n",
       "           -9.2149e-01, -1.1640e+00]],\n",
       "\n",
       "         [[-1.1217e+00, -5.1537e-01, -9.4099e-01,  ..., -4.3875e-01,\n",
       "           -1.0507e+00, -2.6148e-01],\n",
       "          [-1.8716e+00, -1.1463e+00, -1.7432e+00,  ..., -1.2590e-01,\n",
       "           -1.3466e+00, -8.8341e-01],\n",
       "          [-2.8286e-01, -8.4167e-01, -4.8598e-01,  ..., -1.0491e-01,\n",
       "           -9.4246e-01, -1.2264e+00],\n",
       "          ...,\n",
       "          [-1.0114e+00, -1.5403e+00, -1.2718e+00,  ..., -6.9153e-01,\n",
       "           -1.0353e+00, -6.5931e-01],\n",
       "          [-2.1648e+00, -5.4565e-01, -5.4402e-01,  ..., -8.1402e-01,\n",
       "           -2.0280e+00, -5.2083e-01],\n",
       "          [ 6.2025e-02, -4.2551e-01, -6.4577e-01,  ..., -1.1053e+00,\n",
       "           -1.5719e-01, -1.2092e+00]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_8_ = batchnorm(Input, running_mean, running_var, momentum=0.1, eps=1e-05)\n",
    "output_8_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8506e-15)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_8 = torch.nn.functional.mse_loss(output_8,output_8_)\n",
    "error_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 9: torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 1,  ..., 1, 2, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 2],\n",
       "         [0, 2, 1,  ..., 1, 2, 0],\n",
       "         ...,\n",
       "         [0, 2, 1,  ..., 0, 0, 2],\n",
       "         [2, 2, 0,  ..., 1, 2, 1],\n",
       "         [1, 0, 1,  ..., 0, 2, 0]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(0,3, (1,32,32), dtype=torch.int64)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3646)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_9 = torch.nn.functional.cross_entropy(Input, target,weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "output_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    maxes = torch.max(x, 1, keepdim=True)[0]\n",
    "    x_exp = torch.exp(x-maxes)\n",
    "    x_exp_sum = torch.sum(x_exp, 1, keepdim=True)\n",
    "\n",
    "    return x_exp/x_exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3646, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Input_softmax = np.array(softmax(Input)[0])\n",
    "target = np.array(target)\n",
    "loss = 0.0\n",
    "for b in range(target.shape[0]):\n",
    "    for i in range(target.shape[1]):\n",
    "        for j in range(target.shape[2]):\n",
    "            loss -= np.log(Input_softmax[target[b][i][j]][i][j])/1024\n",
    "print(torch.tensor(loss))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 10: torch.nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0336)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(1,3,32,32)\n",
    "output_10 = torch.nn.functional.mse_loss(Input, target, size_average=None, reduce=None, reduction='mean')\n",
    "output_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(inp,target):\n",
    "    MSE = np.square(np.subtract(inp,target)).mean()\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0336)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_10_ = mse(Input, target)\n",
    "output_10_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
